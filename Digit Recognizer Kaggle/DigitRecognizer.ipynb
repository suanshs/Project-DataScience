{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from os.path import isfile, isdir\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in train & test csv\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in train data: 42000\n",
      "\n",
      "Number of Samples in test data: 8400\n"
     ]
    }
   ],
   "source": [
    "print('Number of Samples in train data:',train.shape[0])\n",
    "print()\n",
    "print('Number of Samples in test data:', test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEVFLEkdERNSSxBEREbX8D0zfIO07k+j/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16e90db75c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(train[['pixel0','label']].groupby('label').count())\n",
    "import matplotlib.pyplot as plt\n",
    "y_pos = np.arange(10)\n",
    "objects  = range(0,10)\n",
    "plt.bar(y_pos,df.pixel0.values)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel(\"Count in Train Data Set\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.title(\"Count of Each Class in Train Data Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the above chart that the there is  uniform distribution in the train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState()\n",
    "def batch_creator(batch_size, dataset_length, dataset_name):\n",
    "    \"\"\"Create batch with random samples and return appropriate format\"\"\"\n",
    "    batch_mask = rng.choice(dataset_length, batch_size)\n",
    "    \n",
    "    batch_x = eval(dataset_name + '_x')[[batch_mask]].reshape(-1, 784)\n",
    "    \n",
    "    batch_y = eval(dataset_name + '_y')[[batch_mask]].reshape(-1, 10)\n",
    "    return(batch_x,batch_y)\n",
    "\n",
    "def imageMatrix(df, n):\n",
    "    img = df.iloc[n,:].values.reshape(-1,28,28)\n",
    "    return(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata_x = test.iloc[:,range(0,784)].values/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am running a multi layer perceptron with one hidden layer having 500 hidden units. I am using relu activation function and adam optimizer. I am using stratified 5-fold cross validation to repeat the experiment. I am also using a convolution neural network to compare the results with vanilla neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results For Repetiton: 1\n",
      "Epoch: 1 cost = 0.288 Accuracy: 0.955741\n",
      "Epoch: 2 cost = 0.101 Accuracy: 0.961452\n",
      "Epoch: 3 cost = 0.083 Accuracy: 0.95931\n",
      "Epoch: 4 cost = 0.064 Accuracy: 0.961689\n",
      "Epoch: 5 cost = 0.061 Accuracy: 0.965497\n",
      "Epoch: 6 cost = 0.053 Accuracy: 0.965378\n",
      "Epoch: 7 cost = 0.051 Accuracy: 0.960143\n",
      "Epoch: 8 cost = 0.049 Accuracy: 0.966805\n",
      "Epoch: 9 cost = 0.057 Accuracy: 0.965616\n",
      "Epoch: 10 cost = 0.039 Accuracy: 0.967757\n",
      "Final Accuracy For Repetition  1 : 0.967757\n",
      "Results For Repetiton: 2\n",
      "Epoch: 1 cost = 0.268 Accuracy: 0.952279\n",
      "Epoch: 2 cost = 0.107 Accuracy: 0.963227\n",
      "Epoch: 3 cost = 0.084 Accuracy: 0.956682\n",
      "Epoch: 4 cost = 0.065 Accuracy: 0.960966\n",
      "Epoch: 5 cost = 0.061 Accuracy: 0.957753\n",
      "Epoch: 6 cost = 0.058 Accuracy: 0.962751\n",
      "Epoch: 7 cost = 0.049 Accuracy: 0.962275\n",
      "Epoch: 8 cost = 0.047 Accuracy: 0.968583\n",
      "Epoch: 9 cost = 0.047 Accuracy: 0.96775\n",
      "Epoch: 10 cost = 0.045 Accuracy: 0.967869\n",
      "Final Accuracy For Repetition  2 : 0.967869\n",
      "Results For Repetiton: 3\n",
      "Epoch: 1 cost = 0.272 Accuracy: 0.947613\n",
      "Epoch: 2 cost = 0.103 Accuracy: 0.953566\n",
      "Epoch: 3 cost = 0.079 Accuracy: 0.961424\n",
      "Epoch: 4 cost = 0.068 Accuracy: 0.960829\n",
      "Epoch: 5 cost = 0.064 Accuracy: 0.961781\n",
      "Epoch: 6 cost = 0.055 Accuracy: 0.962257\n",
      "Epoch: 7 cost = 0.048 Accuracy: 0.965353\n",
      "Epoch: 8 cost = 0.045 Accuracy: 0.964281\n",
      "Epoch: 9 cost = 0.046 Accuracy: 0.962496\n",
      "Epoch: 10 cost = 0.049 Accuracy: 0.962376\n",
      "Final Accuracy For Repetition  3 : 0.962376\n",
      "Results For Repetiton: 4\n",
      "Epoch: 1 cost = 0.257 Accuracy: 0.946886\n",
      "Epoch: 2 cost = 0.105 Accuracy: 0.961653\n",
      "Epoch: 3 cost = 0.080 Accuracy: 0.955103\n",
      "Epoch: 4 cost = 0.068 Accuracy: 0.957128\n",
      "Epoch: 5 cost = 0.060 Accuracy: 0.971895\n",
      "Epoch: 6 cost = 0.057 Accuracy: 0.959628\n",
      "Epoch: 7 cost = 0.050 Accuracy: 0.966059\n",
      "Epoch: 8 cost = 0.054 Accuracy: 0.961891\n",
      "Epoch: 9 cost = 0.063 Accuracy: 0.967369\n",
      "Epoch: 10 cost = 0.037 Accuracy: 0.971299\n",
      "Final Accuracy For Repetition  4 : 0.971299\n",
      "Results For Repetiton: 5\n",
      "Epoch: 1 cost = 0.264 Accuracy: 0.954145\n",
      "Epoch: 2 cost = 0.111 Accuracy: 0.964507\n",
      "Epoch: 3 cost = 0.082 Accuracy: 0.957956\n",
      "Epoch: 4 cost = 0.070 Accuracy: 0.962125\n",
      "Epoch: 5 cost = 0.061 Accuracy: 0.967961\n",
      "Epoch: 6 cost = 0.058 Accuracy: 0.967008\n",
      "Epoch: 7 cost = 0.046 Accuracy: 0.968199\n",
      "Epoch: 8 cost = 0.041 Accuracy: 0.967842\n",
      "Epoch: 9 cost = 0.050 Accuracy: 0.967008\n",
      "Epoch: 10 cost = 0.050 Accuracy: 0.968199\n",
      "Final Accuracy For Repetition  5 : 0.968199\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "accuracy_NN = []\n",
    "kf = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "kf.get_n_splits(train)\n",
    "for train_index, val_index in kf.split(train, train.label):\n",
    "    #Train Data\n",
    "    traindata_x = train.iloc[train_index,range(1,785)].values/255\n",
    "    enc = OneHotEncoder(sparse = False)\n",
    "    traindata_y = enc.fit_transform(train.iloc[train_index,0].values.reshape(len(train_index), 1))\n",
    "    #Validation Data\n",
    "    #validation Data\n",
    "    valdata_x = train.iloc[val_index,range(1,785)].values/255\n",
    "    valdata_y = enc.fit_transform(train.iloc[val_index,0].values.reshape(len(val_index), 1))\n",
    "    #Declaring the neural network parameters\n",
    "    learning_rate = 0.01\n",
    "    epochs = 10\n",
    "    batch_size = 128\n",
    "    #Declaring the input and output placeholders\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    y = tf.placeholder(tf.float32, [None, 10])\n",
    "    # now declare the weights connecting the input to the hidden layer\n",
    "    W1 = tf.Variable(tf.random_normal([784, 500], stddev=0.03), name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal([500]), name='b1')\n",
    "    # and the weights connecting the hidden layer to the output layer\n",
    "    W2 = tf.Variable(tf.random_normal([500, 10], stddev=0.03), name='W2')\n",
    "    b2 = tf.Variable(tf.random_normal([10]), name='b2')\n",
    "    # calculate the output of the hidden layer\n",
    "    hidden_out = tf.add(tf.matmul(x, W1), b1)\n",
    "    hidden_out = tf.nn.relu(hidden_out)\n",
    "    # now calculate the hidden layer output - in this case, let's use a softmax activated\n",
    "    # output layer\n",
    "    output_layer = tf.matmul(hidden_out, W2) + b2\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = output_layer,labels=  y))\n",
    "    optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # finally setup the initialisation operator\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    # define an accuracy assessment operation\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(output_layer, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    print(\"Results For Repetiton:\", count)\n",
    "    # start the session\n",
    "    with tf.Session() as sess:\n",
    "        # initialise the variables\n",
    "        sess.run(init_op)\n",
    "        total_batch = int(len(traindata_x) / batch_size)\n",
    "        for epoch in range(epochs):\n",
    "            avg_cost = 0\n",
    "            for i in range(total_batch):\n",
    "                batch_x, batch_y = batch_creator(128, len(traindata_x), 'traindata')\n",
    "                _, c= sess.run([optimiser, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "                avg_cost += c / total_batch\n",
    "            print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost),\n",
    "                  \"Accuracy:\", sess.run(accuracy, feed_dict={x: valdata_x, y: valdata_y}))\n",
    "        print(\"Final Accuracy For Repetition \", count,\":\", sess.run(accuracy, feed_dict={x: valdata_x, y: valdata_y}))\n",
    "        accuracy_NN.extend([sess.run(accuracy, feed_dict={x: valdata_x, y: valdata_y})])\n",
    "        count = count+1\n",
    "        predict = tf.argmax(output_layer, 1)\n",
    "        pred_NN = predict.eval({x: testdata_x.reshape(-1, 784)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Number:  2\n",
      "\n",
      "The actual image is shown below:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAOHngXwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16e9ea57470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "which = 3898\n",
    "print(\"Predicted Number: \",pred[which])\n",
    "print()\n",
    "print(\"The actual image is shown below:\")\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(imageMatrix(test, which), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using convolution neural network with two convolution layer with 6 and 16 filters. I am also using a fully dense layer with 128 perceptrons and an output layer with 10 perceptrons. I am using pooling and relu layers in between as well. I am using the same stratified 5 fold cross validation for repetitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results For Repetiton: 1\n",
      "Epoch: 1 cost = 0.290 Accuracy: 0.974539\n",
      "Epoch: 2 cost = 0.078 Accuracy: 0.981321\n",
      "Epoch: 3 cost = 0.056 Accuracy: 0.978108\n",
      "Epoch: 4 cost = 0.052 Accuracy: 0.97906\n",
      "Epoch: 5 cost = 0.044 Accuracy: 0.982153\n",
      "Epoch: 6 cost = 0.042 Accuracy: 0.979893\n",
      "Epoch: 7 cost = 0.038 Accuracy: 0.97906\n",
      "Epoch: 8 cost = 0.038 Accuracy: 0.98251\n",
      "Epoch: 9 cost = 0.036 Accuracy: 0.978346\n",
      "Epoch: 10 cost = 0.034 Accuracy: 0.979417\n",
      "Final Accuracy for repetition 1 : 0.979417\n",
      "Results For Repetiton: 2\n",
      "Epoch: 1 cost = 0.282 Accuracy: 0.97013\n",
      "Epoch: 2 cost = 0.071 Accuracy: 0.979531\n",
      "Epoch: 3 cost = 0.053 Accuracy: 0.983339\n",
      "Epoch: 4 cost = 0.044 Accuracy: 0.981078\n",
      "Epoch: 5 cost = 0.040 Accuracy: 0.982268\n",
      "Epoch: 6 cost = 0.039 Accuracy: 0.986076\n",
      "Epoch: 7 cost = 0.034 Accuracy: 0.981673\n",
      "Epoch: 8 cost = 0.031 Accuracy: 0.981554\n",
      "Epoch: 9 cost = 0.035 Accuracy: 0.981078\n",
      "Epoch: 10 cost = 0.040 Accuracy: 0.978817\n",
      "Final Accuracy for repetition 2 : 0.978817\n",
      "Results For Repetiton: 3\n",
      "Epoch: 1 cost = 0.310 Accuracy: 0.967377\n",
      "Epoch: 2 cost = 0.087 Accuracy: 0.965472\n",
      "Epoch: 3 cost = 0.072 Accuracy: 0.97595\n",
      "Epoch: 4 cost = 0.056 Accuracy: 0.972616\n",
      "Epoch: 5 cost = 0.054 Accuracy: 0.970354\n",
      "Epoch: 6 cost = 0.052 Accuracy: 0.978212\n",
      "Epoch: 7 cost = 0.043 Accuracy: 0.979045\n",
      "Epoch: 8 cost = 0.047 Accuracy: 0.976426\n",
      "Epoch: 9 cost = 0.048 Accuracy: 0.982141\n",
      "Epoch: 10 cost = 0.035 Accuracy: 0.982617\n",
      "Final Accuracy for repetition 3 : 0.982617\n",
      "Results For Repetiton: 4\n",
      "Epoch: 1 cost = 0.272 Accuracy: 0.959152\n",
      "Epoch: 2 cost = 0.077 Accuracy: 0.971299\n",
      "Epoch: 3 cost = 0.059 Accuracy: 0.974872\n",
      "Epoch: 4 cost = 0.050 Accuracy: 0.978564\n",
      "Epoch: 5 cost = 0.042 Accuracy: 0.974991\n",
      "Epoch: 6 cost = 0.044 Accuracy: 0.976063\n",
      "Epoch: 7 cost = 0.040 Accuracy: 0.97773\n",
      "Epoch: 8 cost = 0.039 Accuracy: 0.977135\n",
      "Epoch: 9 cost = 0.034 Accuracy: 0.979159\n",
      "Epoch: 10 cost = 0.031 Accuracy: 0.97904\n",
      "Final Accuracy for repetition 4 : 0.97904\n",
      "Results For Repetiton: 5\n",
      "Epoch: 1 cost = 0.438 Accuracy: 0.950453\n",
      "Epoch: 2 cost = 0.099 Accuracy: 0.967485\n",
      "Epoch: 3 cost = 0.076 Accuracy: 0.970224\n",
      "Epoch: 4 cost = 0.068 Accuracy: 0.974631\n",
      "Epoch: 5 cost = 0.064 Accuracy: 0.975941\n",
      "Epoch: 6 cost = 0.056 Accuracy: 0.979752\n",
      "Epoch: 7 cost = 0.054 Accuracy: 0.971772\n",
      "Epoch: 8 cost = 0.049 Accuracy: 0.969628\n",
      "Epoch: 9 cost = 0.046 Accuracy: 0.977489\n",
      "Epoch: 10 cost = 0.042 Accuracy: 0.975584\n",
      "Final Accuracy for repetition 5 : 0.975584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "count = 1\n",
    "accuracy_CNN = []\n",
    "kf = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "kf.get_n_splits(train)\n",
    "for train_index, val_index in kf.split(train,train.label):\n",
    "    #Train Data\n",
    "    traindata_x = train.iloc[train_index,range(1,785)].values/255\n",
    "    enc = OneHotEncoder(sparse = False)\n",
    "    traindata_y = enc.fit_transform(train.iloc[train_index,0].values.reshape(len(train_index), 1))\n",
    "    #Validation Data\n",
    "    #validation Data\n",
    "    valdata_x = train.iloc[val_index,range(1,785)].values/255\n",
    "    valdata_y = enc.fit_transform(train.iloc[val_index,0].values.reshape(len(val_index), 1))\n",
    "    #Declaring the neural network parameters\n",
    "    learning_rate = 0.01\n",
    "    epochs = 10\n",
    "    batch_size = 128\n",
    "    #Defining the placeholders\n",
    "    #Placeholder variable for the input images\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 28*28], name='X')\n",
    "    # Reshape it into [num_images, img_height, img_width, num_channels]\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    y = tf.placeholder(tf.float32, [None, 10])\n",
    "    \n",
    "    \n",
    "    #weights and biases for first convolution layer\n",
    "    W1 = tf.Variable(tf.truncated_normal([5,5,1,6], stddev=0.03))\n",
    "    b1 = tf.Variable(tf.constant(0.03, shape=[6]))\n",
    "\n",
    "    #First Convlution Layer\n",
    "    conv1 = tf.add(tf.nn.conv2d(input=x_image, filter=W1, strides=[1, 1, 1, 1], padding='SAME'),b1)\n",
    "    #First Pooling Layer\n",
    "    pool1 = tf.nn.max_pool(value=conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    #First Relu Layer\n",
    "    relu1 = tf.nn.relu(pool1)\n",
    "\n",
    "    #Weights and biases for second convolution layer\n",
    "    W2 = tf.Variable(tf.truncated_normal([5,5,6,16], stddev=0.03))\n",
    "    b2 = tf.Variable(tf.constant(0.03, shape=[16]))\n",
    "\n",
    "    #Second convolution layer\n",
    "    conv2 = tf.add(tf.nn.conv2d(input=relu1, filter=W2, strides=[1, 1, 1, 1], padding='SAME'),b2)\n",
    "    pool2 = tf.nn.max_pool(value=conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    relu2 = tf.nn.relu(pool2)\n",
    "    num_features = relu2.get_shape()[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(relu2, [-1, num_features])\n",
    "\n",
    "    #Weights and biases for first fully connected layer\n",
    "    W3 = tf.Variable(tf.truncated_normal([num_features, 128], stddev=0.03))\n",
    "    b3 = tf.Variable(tf.constant(0.03, shape=[128]))\n",
    "\n",
    "    fc1 = tf.matmul(layer_flat, W3) + b3\n",
    "    relu3 = tf.nn.relu(fc1)\n",
    "\n",
    "    W4 = tf.Variable(tf.truncated_normal([128, 10], stddev=0.03))\n",
    "    b4 = tf.Variable(tf.constant(0.03, shape=[10]))\n",
    "\n",
    "    fc2 = tf.matmul(relu3, W4) + b4\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = fc2,labels=  y))\n",
    "    optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # finally setup the initialisation operator\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    # define an accuracy assessment operation\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(fc2, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # start the session\n",
    "    print(\"Results For Repetiton:\", count)\n",
    "    with tf.Session() as sess:\n",
    "        # initialise the variables\n",
    "        sess.run(init_op)\n",
    "        total_batch = int(len(traindata_x) / batch_size)\n",
    "        for epoch in range(epochs):\n",
    "            avg_cost = 0\n",
    "            for i in range(total_batch):\n",
    "                batch_x, batch_y = batch_creator(128, len(traindata_x), 'traindata')\n",
    "                _, c= sess.run([optimiser, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "                avg_cost += c / total_batch\n",
    "            print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost),\n",
    "                  \"Accuracy:\", sess.run(accuracy, feed_dict={x: valdata_x, y: valdata_y}))\n",
    "        print(\"Final Accuracy for repetition\", count,\":\", sess.run(accuracy, feed_dict={x: valdata_x, y: valdata_y}))\n",
    "        \n",
    "        accuracy_CNN.extend([sess.run(accuracy, feed_dict={x: valdata_x, y: valdata_y})])\n",
    "        count = count + 1\n",
    "        predict = tf.argmax(fc2, 1)\n",
    "        pred = predict.eval({x: testdata_x.reshape(-1, 784)})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy with neural networks: 0.9675\n",
      "\n",
      "Meanaccuracy with convolution neural networks: 0.979095\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy with neural networks:\", np.mean(accuracy_NN))\n",
    "print()\n",
    "print(\"Meanaccuracy with convolution neural networks:\",np.mean(accuracy_CNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result show that CNN perform slightly better than the multi layer perceptrons. The CNN while on the other hald due to its complex design takes very long train and has a high number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
